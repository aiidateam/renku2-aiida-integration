{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "manual-setup"
    ]
   },
   "source": [
    "# Exploring AiiDA archives\n",
    "\n",
    "For more information see [the AiiDA documentation](https://aiida.readthedocs.io/projects/aiida-core/en/latest/howto/data.html).\n",
    "\n",
    "To explore a custom archive, you should first make it available in your RenkuLab session, e.g., via download through `wget` in a terminal launcher.\n",
    "\n",
    "Then, you can run either:\n",
    "\n",
    "```shell\n",
    "‚ùØ verdi profile setup core.sqlite_zip --filepath <your-archive>.aiida\n",
    "```\n",
    "\n",
    "to create a read-only AiiDA profile from the archive, or:\n",
    "\n",
    "```shell\n",
    "‚ùØ verdi presto\n",
    "‚ùØ verdi archive import <your-archive>.aiida\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "archive-setup"
    ]
   },
   "source": [
    "# Live inspection of provenance from an AiiDA archive\n",
    "## Dataset: {{ title }}\n",
    "* DOI of the data: [{{ doi_url }}]({{ doi_url }})\n",
    "* Materials Cloud Archive entry: `{{ mca_entry }}`\n",
    "* Archive file: `{{ archive_filename }}`\n",
    "* AiiDA profile name: `{{ aiida_profile }}`\n",
    "\n",
    "## Instructions\n",
    "This session is configured to work with the archive file mentioned above. The archive has not been downloaded yet to keep startup fast.\n",
    "\n",
    "**Follow these steps:**\n",
    "1. **Run the cells below** to download the archive and set up AiiDA\n",
    "2. **Start exploring** using the AiiDA commands and examples\n",
    "\n",
    "**NOTE**: *If you were expecting a different archive or file, you probably already have an open Renku session. Each Renku user can only have one session at a given time. To see the new file, close the current session by clicking on the trash button on the top left corner of this browser window, and then click again on the file in Materials Cloud Archive to open a new session pointing to the file you want.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "archive-setup"
    ]
   },
   "outputs": [],
   "source": [
    "# Check for session warnings\n",
    "import os\n",
    "warning_file = '/tmp/session_warning.txt'\n",
    "if os.path.exists(warning_file):\n",
    "    with open(warning_file, 'r') as f:\n",
    "        print(f.read())\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "archive-setup"
    ]
   },
   "source": [
    "## Step 1: Download the Archive\n",
    "This cell will download the archive file from Materials Cloud Archive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "archive-setup"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "# Load metadata from JSON file\n",
    "metadata_file = '/tmp/mca_metadata.json'\n",
    "\n",
    "if not os.path.exists(metadata_file):\n",
    "    print(\"‚ùå No metadata file found. Please run the session setup first.\")\n",
    "else:\n",
    "    with open(metadata_file, 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "    \n",
    "    # Extract information from metadata\n",
    "    archive_url = os.environ.get('archive_url')  # Still get this from env as it's the trigger\n",
    "    archive_filename = metadata.get('archive_filename')\n",
    "    archive_title = metadata.get('title', 'Unknown Dataset')\n",
    "    doi = metadata.get('doi')\n",
    "    mca_entry = metadata.get('mca_entry')\n",
    "    \n",
    "    if not archive_url:\n",
    "        print(\"‚ùå No archive URL found. This cell is only for pre-configured archives.\")\n",
    "    elif not archive_filename:\n",
    "        print(\"‚ùå No archive filename found in metadata.\")\n",
    "    else:\n",
    "        print(f\"üì¶ Dataset: {archive_title}\")\n",
    "        print(f\"üìÅ Archive file: {archive_filename}\")\n",
    "        print(f\"üîó Source URL: {archive_url}\")\n",
    "        if doi:\n",
    "            print(f\"üìÑ DOI: {doi}\")\n",
    "        if mca_entry:\n",
    "            print(f\"üè∑Ô∏è MCA Entry: {mca_entry}\")\n",
    "        print(\"\")\n",
    "        \n",
    "        # Create data directory\n",
    "        data_dir = Path('aiida_data')\n",
    "        data_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        archive_path = data_dir / archive_filename\n",
    "        \n",
    "        if archive_path.exists():\n",
    "            size_mb = archive_path.stat().st_size / (1024*1024)\n",
    "            print(f\"‚úÖ Archive already exists ({size_mb:.1f} MB)\")\n",
    "        else:\n",
    "            print(\"‚¨áÔ∏è Downloading archive... (this may take a moment)\")\n",
    "            \n",
    "            try:\n",
    "                result = subprocess.run(\n",
    "                    ['wget', '-q', '--show-progress', '-O', str(archive_path), archive_url],\n",
    "                    capture_output=True, text=True, check=True\n",
    "                )\n",
    "                \n",
    "                size_mb = archive_path.stat().st_size / (1024*1024)\n",
    "                print(f\"\\n‚úÖ Archive downloaded successfully ({size_mb:.1f} MB)\")\n",
    "                \n",
    "            except subprocess.CalledProcessError as e:\n",
    "                print(f\"‚ùå Download failed: {e}\")\n",
    "                print(f\"You can try downloading manually with: wget '{archive_url}' -O {archive_path}\")\n",
    "            except FileNotFoundError:\n",
    "                print(\"‚ùå wget not found. Trying with Python...\")\n",
    "                \n",
    "                # Fallback to Python download\n",
    "                import urllib.request\n",
    "                from urllib.error import URLError\n",
    "                \n",
    "                try:\n",
    "                    print(\"‚¨áÔ∏è Downloading with Python... (no progress bar)\")\n",
    "                    urllib.request.urlretrieve(archive_url, archive_path)\n",
    "                    size_mb = archive_path.stat().st_size / (1024*1024)\n",
    "                    print(f\"‚úÖ Archive downloaded successfully ({size_mb:.1f} MB)\")\n",
    "                except URLError as e:\n",
    "                    print(f\"‚ùå Python download also failed: {e}\")\n",
    "        \n",
    "        print(f\"\\nüìç Archive location: {archive_path.absolute()}\")\n",
    "        \n",
    "        # Display additional metadata if available\n",
    "        files_info = metadata.get('files', [])\n",
    "        if files_info:\n",
    "            print(f\"\\nüìä Dataset contains {len(files_info)} files:\")\n",
    "            for file_info in files_info:\n",
    "                filename = file_info.get('filename', 'Unknown')\n",
    "                file_type = file_info.get('type', 'unknown')\n",
    "                size = file_info.get('size')\n",
    "                if size:\n",
    "                    size_str = f\" ({size / (1024*1024):.1f} MB)\" if size > 1024*1024 else f\" ({size / 1024:.1f} KB)\"\n",
    "                else:\n",
    "                    size_str = \"\"\n",
    "                print(f\"   ‚Ä¢ {filename} ({file_type}){size_str}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "archive-setup"
    ]
   },
   "source": [
    "## Step 2: Set up AiiDA Profile\n",
    "This cell creates a read-only AiiDA profile from the downloaded archive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "archive-setup"
    ]
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Get profile information\n",
    "profile_name = os.environ.get('MCA_AIIDA_PROFILE', 'aiida-renku')\n",
    "archive_filename = os.environ.get('MCA_ARCHIVE_FILENAME')\n",
    "archive_path = Path('aiida_data') / archive_filename\n",
    "\n",
    "if not archive_path.exists():\n",
    "    print(\"‚ùå Archive file not found. Please run the download cell above first.\")\n",
    "else:\n",
    "    print(f\"üîß Setting up AiiDA profile: {profile_name}\")\n",
    "    print(f\"üìÅ Using archive: {archive_path}\")\n",
    "    print(\"\")\n",
    "    \n",
    "    # Check if profile already exists\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            ['verdi', 'profile', 'show', profile_name],\n",
    "            capture_output=True, text=True, check=True\n",
    "        )\n",
    "        print(f\"‚úÖ Profile '{profile_name}' already exists\")\n",
    "        \n",
    "    except subprocess.CalledProcessError:\n",
    "        # Profile doesn't exist, create it\n",
    "        print(\"‚öôÔ∏è Creating AiiDA profile... (this may take a few minutes)\")\n",
    "        \n",
    "        try:\n",
    "            result = subprocess.run([\n",
    "                'verdi', 'profile', 'setup', 'core.sqlite_zip',\n",
    "                '--profile-name', profile_name,\n",
    "                '--first-name', 'AiiDA',\n",
    "                '--last-name', 'User', \n",
    "                '--email', 'aiida@renku.local',\n",
    "                '--institution', 'RenkuLab',\n",
    "                '--set-as-default',\n",
    "                '--non-interactive',\n",
    "                '--no-use-rabbitmq',\n",
    "                '--filepath', str(archive_path.absolute())\n",
    "            ], capture_output=True, text=True, check=True)\n",
    "            \n",
    "            print(f\"‚úÖ Profile '{profile_name}' created successfully!\")\n",
    "            \n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"‚ùå Failed to create profile: {e}\")\n",
    "            print(f\"Error output: {e.stderr}\")\n",
    "            print(\"\\nYou can try creating the profile manually with:\")\n",
    "            print(f\"verdi profile setup core.sqlite_zip --filepath {archive_path}\")\n",
    "    \n",
    "    # Set as default profile\n",
    "    try:\n",
    "        subprocess.run(['verdi', 'profile', 'setdefault', profile_name], \n",
    "                      capture_output=True, check=True)\n",
    "        print(f\"üéØ Profile '{profile_name}' set as default\")\n",
    "    except subprocess.CalledProcessError:\n",
    "        print(\"‚ö†Ô∏è Could not set as default profile, but it should still work\")\n",
    "    \n",
    "    print(\"\\nüéâ AiiDA setup complete! You can now explore the archive data below.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Load AiiDA and Start Exploring\n",
    "Now you can start exploring the AiiDA database!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida import orm, load_profile\n",
    "\n",
    "# Load the AiiDA profile\n",
    "profile = load_profile()\n",
    "print(f\"‚úÖ Loaded AiiDA profile: {profile.name}\")\n",
    "print(f\"üìä Profile storage: {profile.storage}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get basic statistics about the database\n",
    "qb = orm.QueryBuilder()\n",
    "qb.append(orm.Node)\n",
    "total_nodes = qb.count()\n",
    "print(f\"üìà Total number of nodes in the database: {total_nodes:,}\")\n",
    "\n",
    "# Show different types of nodes\n",
    "from collections import defaultdict\n",
    "\n",
    "node_types = defaultdict(int)\n",
    "qb = orm.QueryBuilder()\n",
    "qb.append(orm.Node, project=['node_type'])\n",
    "\n",
    "for node_type, in qb.iterall():\n",
    "    # Simplify node type names for readability\n",
    "    short_type = node_type.split('.')[-1] if '.' in node_type else node_type\n",
    "    node_types[short_type] += 1\n",
    "\n",
    "print(\"\\nüìã Node types in the database:\")\n",
    "for node_type, count in sorted(node_types.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"   {node_type:<25} {count:>8,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show available groups\n",
    "qb = orm.QueryBuilder()\n",
    "qb.append(orm.Group, project=['label', 'description', 'extras'])\n",
    "\n",
    "groups = list(qb.iterall())\n",
    "print(f\"üë• Available groups ({len(groups)} total):\")\n",
    "print()\n",
    "\n",
    "for label, description, extras in groups:\n",
    "    print(f\"üìÅ {label}\")\n",
    "    if description:\n",
    "        print(f\"   Description: {description}\")\n",
    "    \n",
    "    # Count nodes in this group\n",
    "    try:\n",
    "        group = orm.Group.get(label=label)\n",
    "        node_count = group.count()\n",
    "        print(f\"   Nodes: {node_count:,}\")\n",
    "    except:\n",
    "        pass\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Exploration\n",
    "\n",
    "You can now use all AiiDA functionality to explore the archive. Here are some useful commands to get you started:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Find and examine calculation nodes\n",
    "qb = orm.QueryBuilder()\n",
    "qb.append(orm.CalcJobNode, project=['id', 'ctime', 'process_state'], limit=10)\n",
    "\n",
    "calculations = list(qb.iterall())\n",
    "if calculations:\n",
    "    print(f\"üî¨ Recent calculations (showing {len(calculations)} of many):\")\n",
    "    print()\n",
    "    for calc_id, ctime, state in calculations:\n",
    "        print(f\"   Calculation {calc_id}: {state} (created: {ctime.strftime('%Y-%m-%d %H:%M')})\")\n",
    "else:\n",
    "    print(\"No calculation nodes found in this archive.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Explore structures\n",
    "qb = orm.QueryBuilder()\n",
    "qb.append(orm.StructureData, project=['id', 'extras'], limit=5)\n",
    "\n",
    "structures = list(qb.iterall())\n",
    "if structures:\n",
    "    print(f\"üèóÔ∏è Structure data (showing {len(structures)} of many):\")\n",
    "    print()\n",
    "    for struct_id, extras in structures:\n",
    "        structure = orm.load_node(struct_id)\n",
    "        formula = structure.get_formula()\n",
    "        num_atoms = len(structure.sites)\n",
    "        print(f\"   Structure {struct_id}: {formula} ({num_atoms} atoms)\")\n",
    "else:\n",
    "    print(\"No structure data found in this archive.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Data for External Analysis\n",
    "\n",
    "You can also export data to disk for analysis with other tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and modify these commands to export specific data:\n",
    "\n",
    "# Export all data from the profile\n",
    "# !verdi profile dump --all\n",
    "\n",
    "# Export specific group data \n",
    "# !verdi group dump <group-name>\n",
    "\n",
    "# Export specific nodes\n",
    "# !verdi export create -N <node-id> export.aiida\n",
    "\n",
    "print(\"üí° Uncomment the commands above to export data for external analysis\")\n",
    "print(\"üìö Check the AiiDA documentation for more export options: https://aiida.readthedocs.io/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
